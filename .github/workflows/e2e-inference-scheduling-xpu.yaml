name: XPU Inference Scheduling Test

on:
  schedule:
    - cron: '0 10 * * *'  # 3AM PST (10:00 UTC)
  workflow_dispatch:
    inputs:
      pr_or_branch:
        description: 'Pull-request number or branch name to test'
        required: true
        default: 'main'
        type: string
      custom_image_tag:
        description: 'Custom XPU image tag to use (optional)'
        required: false
        default: ''
        type: string
  workflow_call:
    inputs:
      pr_or_branch:
        description: 'Pull-request number or branch name to test'
        required: true
        default: 'main'
        type: string
      custom_image_tag:
        description: 'Custom XPU image tag to use (optional)'
        required: false
        default: ''
        type: string
jobs:
  deploy_and_validate:
    runs-on: xpu
    env:
      NAMESPACE: "llm-d-xpu-is"
      GATEWAY_TYPE: "istio"
      RELEASE_NAME_POSTFIX: "r1"
      INFRA_RELEASE_NAME: "infra-r1"
      GAIE_RELEASE_NAME: "gaie-r1"
      MS_RELEASE_NAME: "ms-r1"

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          persist-credentials: false

      - name: Determine if pr_or_branch is a PR number
        id: check_pr
        env:
          PR_OR_BRANCH: ${{ github.event.inputs.pr_or_branch }}
        shell: bash
        run: |
          echo "PR_OR_BRANCH=${PR_OR_BRANCH:-main}" >> "$GITHUB_ENV"
          if [[ "$PR_OR_BRANCH" =~ ^[0-9]+$ ]]; then
            echo "is_pr=true" >> "$GITHUB_OUTPUT"
          elif [[ "${{ github.event_name }}" = "pull_request" ]]; then
            echo "PR_OR_BRANCH=${{ github.event.pull_request.number }}" >> $GITHUB_ENV
            echo "is_pr=true" >> "$GITHUB_OUTPUT"
          else
            echo "is_pr=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Fetch and checkout PR
        if: steps.check_pr.outputs.is_pr == 'true'
        run: |
          git fetch origin pull/"$PR_OR_BRANCH"/head:pr-"$PR_OR_BRANCH"
          git checkout pr-"$PR_OR_BRANCH"

      - name: Checkout branch
        if: steps.check_pr.outputs.is_pr == 'false'
        run: git checkout "$PR_OR_BRANCH"

      - name: Install prerequisites idempotently
        run: |
          ./guides/prereq/client-setup/install-deps.sh | tee ~/install-deps.log

      - name: Install chart dependencies (CRDs and Istio)
        run: |
          cd guides/prereq/gateway-provider
          ./install-gateway-provider-dependencies.sh
          helmfile apply -f istio.helmfile.yaml

      - name: Install monitoring stack
        run: |
          cd docs/monitoring
          ./scripts/install-prometheus-grafana.sh || true

      - name: Create namespace
        run: |
          kubectl create namespace "${NAMESPACE}" || echo "Namespace already exists"

      - name: Create llm-d-hf-token secret
        run: |
          kubectl create secret generic llm-d-hf-token \
            --from-literal="HF_TOKEN=${{ secrets.HF_TOKEN }}" \
            --namespace "${NAMESPACE}" \
            --dry-run=client -o yaml | kubectl apply -f -

      - name: Set image tag for deployment
        id: set_image_tag
        run: |
          CUSTOM_TAG="${{ inputs.custom_image_tag }}"
          if [ -n "${CUSTOM_TAG}" ]; then
            echo "Using custom image tag: ${CUSTOM_TAG}"
            echo "IMAGE_TAG=${CUSTOM_TAG}" >> $GITHUB_ENV
            echo "HELM_SET_IMAGE=--set decode.containers[0].image=ghcr.io/${{ github.repository }}-xpu-dev:${CUSTOM_TAG}" >> $GITHUB_ENV
          else
            echo "Using default image tag from values file"
            echo "HELM_SET_IMAGE=" >> $GITHUB_ENV
          fi

      - name: Deploy guide
        run: |
          cd guides/inference-scheduling

          # Deploy infrastructure and GAIE first (without image override)
          echo "Deploying infrastructure release..."
          RELEASE_NAME_POSTFIX=${RELEASE_NAME_POSTFIX} \
          helmfile apply -e xpu -n "${NAMESPACE}" \
            --selector 'name=infra-inference-scheduling-xpu' \
            | tee ~/inference-scheduling-xpu-deployment.log
          echo "---------------------------------------" >> ~/inference-scheduling-xpu-deployment.log

          echo "Deploying GAIE release..."
          RELEASE_NAME_POSTFIX=${RELEASE_NAME_POSTFIX} \
          helmfile apply -e xpu -n "${NAMESPACE}" \
            --selector 'name=gaie-inference-scheduling-xpu' \
            | tee -a ~/inference-scheduling-xpu-deployment.log
          echo "---------------------------------------" >> ~/inference-scheduling-xpu-deployment.log

          # Deploy model service with image override if provided
          echo "Deploying model service release..."
          if [ -n "${HELM_SET_IMAGE}" ]; then
            echo "Applying custom image settings: ${HELM_SET_IMAGE}"
          fi
          RELEASE_NAME_POSTFIX=${RELEASE_NAME_POSTFIX} \
          helmfile apply -e xpu -n "${NAMESPACE}" \
            --selector 'name=ms-inference-scheduling-xpu' \
            ${HELM_SET_IMAGE} \
            | tee -a ~/inference-scheduling-xpu-deployment.log
          echo "---------------------------------------" >> ~/inference-scheduling-xpu-deployment.log

      - name: fetch helm manifests - prepare for upload
        run: |
          for release_name in "${INFRA_RELEASE_NAME}" "${GAIE_RELEASE_NAME}" "${MS_RELEASE_NAME}"; do
            /bin/sh .github/scripts/e2e/helm-get-all.sh \
              ~/inference-scheduling-xpu-deployment.log \
              "$release_name" \
              "$NAMESPACE"
          done

      - name: Wait for all pods to be ready
        continue-on-error: true
        id: wait_pods
        run: |
          kubectl wait pod \
            --for=condition=Ready \
            --all \
            -n "${NAMESPACE}" \
            --timeout=10m
          sleep 180 # TODO: remove this once examples have readiness probes
          echo "✅ All pods are ready."
          kubectl get pods -n "${NAMESPACE}"

      - name: Check gateway pod is up
        if: always()
        run: |
          GATEWAY_POD_READY=$(kubectl get pods -n "${NAMESPACE}" | grep "inference-gateway" | awk '{print $2}')
          if [ "${GATEWAY_POD_READY}" = "1/1" ]; then
              echo "✅ Gateway pod ready."
          else
              echo "❌ Missing gateway pod"
          fi

      - name: Show deployment status
        if: always()
        run: |
          echo "=== Deployments ==="
          kubectl get deployments -n "${NAMESPACE}"
          echo ""
          echo "=== Replica Sets ==="
          kubectl get replicasets -n "${NAMESPACE}"
          echo ""
          echo "=== Pods ==="
          kubectl get pods -n "${NAMESPACE}"
          echo ""
          echo "=== Services ==="
          kubectl get svc -n "${NAMESPACE}"
          echo ""
          echo "=== Helm releases ==="
          helm list -n "${NAMESPACE}" || true
          echo ""
          echo "=== Inference Pools ==="
          kubectl get inferencepools -n "${NAMESPACE}" || true
          echo ""
          echo "=== HTTPRoutes ==="
          kubectl get httproutes -n "${NAMESPACE}" || true
          echo ""
          echo "=== Gateway ==="
          kubectl get Gateway -n "${NAMESPACE}" || true
          echo ""
          echo "=== Destination Rule ==="
          kubectl get destinationrule -n "${NAMESPACE}" || true
          echo ""

      - name: Verify installation and run inference tests
        if: steps.wait_pods.outcome == 'success'
        run: |
          cd .github/scripts/e2e
          ./e2e-validate.sh -n "${NAMESPACE}" -v

      - name: Collect and upload Kubernetes pod logs
        if: always()
        run: |
            mkdir -p pod-logs-inference-scheduling-xpu
            cd pod-logs-inference-scheduling-xpu
            echo "Fetching ${NAMESPACE} pods log..."
            kubectl get pods -n "${NAMESPACE}" -l "llm-d.ai/role=decode" -o yaml > ./decode-pods.yaml || true
            kubectl logs -n "${NAMESPACE}" -l "llm-d.ai/role=decode" 2>&1 > ./decode-pod-logs.log || true
            kubectl describe pod -n "${NAMESPACE}" -l "llm-d.ai/role=decode" > ./decode-describe-pod-logs.log || true

            echo "Collecting logs from all pods..."
            kubectl get pods -n "${NAMESPACE}" --no-headers -o custom-columns=":metadata.name" \
            | xargs -I{} sh -c 'kubectl logs --all-containers=true -n "${NAMESPACE}" {} > "{}.log" 2>&1' || true
            
            echo "Fetching ${NAMESPACE} pods descriptions..."
            kubectl get pods -n "${NAMESPACE}" --no-headers -o custom-columns=":metadata.name" \
            | xargs -I{} sh -c 'kubectl describe pod -n "${NAMESPACE}" {} > "{}-describe.log" 2>&1' || true
            
            echo "Collecting events..."
            kubectl get events -n "${NAMESPACE}" --sort-by='.lastTimestamp' > events.log 2>&1 || true
            
            mv ~/inference-scheduling-xpu-deployment.log . || true
            mv ~/install-deps.log . || true
            
            echo "Log collection completed."
            ls -la

      - name: Upload pod logs as artifact
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: llmd-pod-logs-inference-scheduling-xpu
          path: pod-logs-inference-scheduling-xpu

      - name: Cleanup deployment
        if: always()
        run: |
          cd guides/inference-scheduling
          helmfile destroy -e xpu -n "${NAMESPACE}"
          kubectl delete ns ${NAMESPACE}